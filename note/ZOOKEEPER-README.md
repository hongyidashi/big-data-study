# ZOOKEEPER
## ZooKeeper基础
1. [ZooKeeper概述](#ZooKeeper概述)
2. [ZooKeeper重要概念](#ZooKeeper重要概念)
3. [ZooKeeper架构](#ZooKeeper架构)

## ZooKeeper深入
1. [什么是ZooKeeper](#什么是ZooKeeper)
   + [一致性问题](#一致性问题)
   + [一致性协议和算法](#一致性协议和算法)
2. [ZAB](#ZAB)
   + [消息广播模式](#消息广播模式)
   + [崩溃恢复模式](#崩溃恢复模式)


## <span id="ZooKeeper概述">ZooKeeper概述</span>
ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、
分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。

Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。

## <span id="ZooKeeper重要概念">ZooKeeper重要概念</span>
**ZooKeeper基础概念**  
- ZooKeeper 本身就是一个分布式程序（只要**半数以上**节点存活，ZooKeeper 就能正常服务）；
- 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），
那么 ZooKeeper 本身仍然是可用的；
- ZooKeeper 将数据保存在内存中，这也就保证了高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，
此限制也是保持 ZNode 中存储的数据量较小的进一步原因）；
- ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态；（“读”多于“写”是协调服务的典型场景。）
- ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除；
持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 Zookeeper 上；
- ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提供数据节点监听服务。


**会话（Session）**  
Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。
客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，
客户端能够通过心跳检测与服务器保持有效的会话，也能够向 Zookeeper 服务器发送请求并接受响应，
同时还能够通过该连接接收来自服务器的 Watch 事件通知。

Session 的 sessionTimeout 值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，
只要在 sessionTimeout 规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，
许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证**全局唯一**。


**Znode**

在 Zookeeper 中，“节点"分为两类，第一类是指构成集群的机器，称之为机器节点；第二类则是指**数据模型中的数据单元**，称之为数据节点一一 ZNode。

>Zookeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree)，由斜杠（/）的进行分割的路径，就是一个 ZNode，
>例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。

在 Zookeeper 中，node 可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个 ZNode 被创建了，除非主动进行ZNode的移除操作，
否则这个 ZNode 将一直保存在 Zookeeper 上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，
那么这个客户端创建的所有临时节点都会被移除。  
另外，ZooKeeper 还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL，一旦节点被标记上这个属性，那么在这个节点被创建的时候，
Zookeeper 会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。

**版本**  
Zookeeper 的每个 ZNode 上都会存储数据，对应于每个 ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，
Stat 中记录了这个 ZNode 的三个数据版本，分别是 version（当前 ZNode 的版本）、
cversion（当前 ZNode 子节点的版本）和 aversion（当前 ZNode 的 ACL 版本）。

**ACL**  
ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限：
- CREATE：创建子节点的权限；
- READ：获取节点数据和子节点列表的权限；
- WRITE：更新节点数据权限；
- DELETE：删除子节点的权限；
- ADMIN：设置节点 ACL 的权限。

**Watcher**  
Watcher（事件监听器），是 Zookeeper 中的一个很重要的特性。Zookeeper 允许用户在指定节点上注册一些 Watcher，
并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 Zookeeper 实现分布式协调服务的重要特性。

**ZooKeeper 特点**  
- 顺序一致性：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去；
- 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用；
- 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的；
- 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

## <span id="ZooKeeper架构">ZooKeeper架构</span>  
![ZooKeeper集群](https://raw.githubusercontent.com/hongyidashi/big-data-study/master/note/images/zookeeper/zk%E9%9B%86%E7%BE%A4.jpg)  

在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。

ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。
除了 Leader 外，Follower 和 Observer 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，
也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。

各个角色作用如下：
![zk集群角色职责](https://raw.githubusercontent.com/hongyidashi/big-data-study/master/note/images/zookeeper/zk%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2%E8%81%8C%E8%B4%A3.jpg)

当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。这个过程大致如下：
1. Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader；
2. Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议；
3. Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本；
同步完成之后准 leader 才会成为真正的 leader；
4. Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。
同时如果有新的节点加入，还需要对新节点进行同步。

## <span id="什么是ZooKeeper">什么是ZooKeeper</span>
ZooKeeper 是一个开源的分布式应用程序协调服务器，其为分布式系统提供一致性服务。其一致性是通过基于 Paxos 算法的 ZAB 协议完成的。
其主要功能包括：配置维护、分布式同步、集群管理、分布式事务等。

### <span id="一致性问题">一致性问题</span>
设计一个分布式系统必定会遇到一个问题 —— 因为 分区容错性（**P**artition tolerance）是必须保证的，
就必定要求我们需要在 系统可用性（**A**vailability）和 数据一致性（**C**onsistency）中做出权衡；这就是 CAP 定理。

### <span id="一致性协议和算法">一致性协议和算法</span>
**2PC（两阶段提交）**  
>PC:phase-commit-阶段提交

在两阶段提交中，主要涉及到两个角色，分别是**协调者**和**参与者**。

第一阶段：当要执行一个分布式事务的时候，事务发起者首先向协调者发起事务请求，然后协调者会给所有参与者发送 prepare 请求（其中包括事务内容），
通知参与者需要执行事务了，如果能执行事务内容那么就先执行但不提交，执行后给协调者答复。然后参与者收到 prepare 消息后，
他们会开始执行事务（但不提交），并将 Undo 和 Redo 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了。

第二阶段：主要是协调者根据参与者反馈的情况来决定接下来是否可以进行事务的提交操作，即提交事务或者回滚事务。

**2PC存在的问题**  
2PC 只解决了各个事务的原子性问题，随之也带来了很多的问题：
- 单点故障问题，如果协调者挂了那么整个系统都处于不可用的状态了；
- 阻塞问题，即当协调者发送 prepare 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，
如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能；
- 数据不一致问题，比如当第二阶段，协调者只发送了一部分的 commit 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，
而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。

---

**3PC（三阶段提交）**
1. CanCommit 阶段：协调者向所有参与者发送 CanCommit 请求，参与者收到请求后会根据自身情况查看是否能执行事务，
如果可以则返回 YES 响应并进入预备状态，否则返回 NO；
2. PreCommit 阶段：协调者根据参与者返回的响应来决定是否可以进行下面的 PreCommit 操作。如果上面参与者返回的都是 YES，
那么协调者将向所有参与者发送 PreCommit 预提交请求，参与者收到预提交请求后，会进行事务的执行操作，并将 Undo 和 Redo 信息写入事务日志中，
最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了任何一个 NO 的信息，
或者在**一定时间内**并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），
参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务；
3. DoCommit阶段：这个阶段其实和 2PC 的第二阶段差不多，如果协调者收到了所有参与者在 PreCommit 阶段的 YES 响应，
那么协调者将会给所有参与者发送 DoCommit 请求，参与者收到 DoCommit 请求后则会进行事务的提交工作，完成后则会给协调者返回响应，
协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 PreCommit 阶段收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应，
那么就会进行中断请求的发送，参与者收到中断请求后则会通过上面记录的回滚日志来进行事务的回滚操作，并向协调者反馈回滚状况，
协调者收到参与者返回的消息后，中断事务。

>3PC 在很多地方进行了超时中断的处理，比如协调者在指定时间内为收到全部的确认消息则进行事务中断的处理，这样能减少同步阻塞的时间。

>3PC 在 DoCommit 阶段参与者如未收到协调者发送的提交事务的请求，它会在一定时间内进行事务的提交。  
>经过了第一阶段可以保证所有的协调者全部返回了可以执行事务的响应，这个时候有理由相信其他系统都能进行事务的执行和提交，
>所以不管协调者有没有发消息给参与者，进入第三阶段参与者都会进行事务的提交操作。

**3PC存在的问题**  
一致性并没有得到根本的解决，比如在 PreCommit 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，
这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。

--- 

**Paxos 算法**  
Paxos 算法是基于**消息传递且具有高度容错特性的一致性算法**，是目前公认的解决分布式一致性问题最有效的算法之一，
其解决的问题就是在分布式系统中如何就某个值（决议）达成一致。

在 Paxos 中主要有三个角色，分别为 Proposer 提案者、Acceptor 表决者、Learner 学习者。Paxos 算法和 2PC 一样，也有两个阶段，
分别为 Prepare 和 accept 阶段。

#### prepare 阶段
Proposer 提案者：负责提出 proposal，每个提案者在提出提案时都会首先获取到一个具有全局唯一性的、递增的提案编号 N，
即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者；
Acceptor 表决者：每个表决者在 accept 某提案后，会将该提案编号 N 记录在本地，
这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。
每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer。

#### accept 阶段
1. 当一个提案被 Proposer 提出后，如果 Proposer 收到了超过半数的 Acceptor 的批准（Proposer 本身同意），
那么此时 Proposer 会给所有的 Acceptor 发送真正的提案（你可以理解为第一阶段为试探），这个时候 Proposer 就会发送提案的内容和提案编号。
2. 表决者 收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号**大于等于**已经批准过的最大提案编号，
那么就 accept 该提案（此时执行提案内容但不提交），随后将情况返回给 Proposer；如果不满足则不回应或者返回 NO。
3. 当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，
因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，
所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，
而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。
4. 而如果 Proposer 如果没有收到超过半数的 accept，那么它将会**递增**该 Proposal 的编号，然后 重新进入 Prepare 阶段 。

#### learn 阶段
Proposer 在收到多数 Acceptors 的 Accept 之后，标志着本次 Accept 成功，决议形成，将形成的决议发送给所有 Learners。

#### paxos 算法的死循环问题
比如说，此时提案者 P1 提出一个方案 M1，完成了 Prepare 阶段的工作，这个时候 acceptor 则批准了 M1，
但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 Prepare 阶段的工作；
然后 P1 的方案已经不能在第二阶段（accept 阶段）被批准了（因为 acceptor 已经批准了比 M1 更大的 M2），
所以 P1 自增方案变为 M3 重新进入 Prepare 阶段，然后 acceptor ，又批准了新的 M3 方案，它又不能批准 M2 了，
这个时候 M2 又自增进入 Prepare 阶段。。。

就这样无休无止的永远提案下去，这就是 paxos 算法的死循环问题。

解决办法：就允许一个能提案，ZooKeeper就是这么个玩意儿。

## <span id="ZAB">ZAB</span>
ZooKeeper 在解决分布式数据一致性问题时并没有直接使用 Paxos ，而是专门定制了一致性协议叫做 ZAB(ZooKeeper Automic Broadcast) 原子广播协议，
该协议能够很好地支持崩溃恢复。

#### ZAB中的三个角色
- Leader：集群中唯一的写请求处理者，能够发起投票（投票也是为了进行写请求）。
- Follower：能够接收客户端的请求，如果是读请求则可以自己处理，如果是写请求则要转发给 Leader。在选举过程中会参与投票，有选举权和被选举权。
- Observer：就是没有选举权和被选举权的 Follower。

在 ZAB 协议中对 zkServer(即上面我们说的三个角色的总称) 还有两种模式的定义，分别是 **消息广播** 和 **崩溃恢复** 。

### <span id="消息广播模式">消息广播模式</span>
说白了就是 ZAB 协议是如何处理写请求的。

第一步需要 Leader 将写请求广播出去，让 Leader 问问 Followers 是否同意更新，
如果超过半数以上的同意那么就进行 Follower 和 Observer 的更新（和 Paxos 一样）。

![消息广播]()

#### FollowerQueues和ObserverQueues
因为ZAB 需要让 Follower 和 Observer 保证顺序性，所以产生了这两个队列。  
何为顺序性，比如现有一个写请求A，此时 Leader 将请求A广播出去，因为只需要半数同意就行，所以可能这个时候有一个 Follower F1因为网络原因没有收到，
而 Leader 又广播了一个请求B，因为网络原因，F1竟然先收到了请求B然后才收到了请求A，这个时候请求处理的顺序不同就会导致数据的不同，
从而 **产生数据不一致问题** 。

所以在 Leader 这端，它为每个其他的 zkServer 准备了一个队列 ，采用先进先出的方式发送消息。由于协议是 **通过 TCP** 来进行网络通信的，
保证了消息的发送顺序性，接受顺序性也得到了保证。

### <span id="崩溃恢复模式">崩溃恢复模式</span>

#### Leade崩溃
系统出现崩溃影响最大应该是 Leader 的崩溃，因为只有一个 Leader ，所以当 Leader 出现问题的时候势必需要重新选举 Leader 。

Leader 选举可以分为两个不同的阶段，第一个是的 Leader 宕机需要重新选举，第二则是当 Zookeeper 启动时需要进行系统的 Leader 初始化选举。

#### 初始化选举

